{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import click\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL.Image\n",
    "import dnnlib\n",
    "from torch_utils import distributed as dist\n",
    "from training.networks import SongUNet, EDMPrecond\n",
    "# dist.init()\n",
    "from generate import edm_sampler, ablation_sampler, StackedRandomGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_save='/data/edm_outputs/00000-FLAIR-uncond-ddpmpp-edm-gpus3-batch15-fp32-FLAIR_ddpm/network-snapshot-001206.pkl'\n",
    "# net_save='/data/edm_outputs/00001-T2-uncond-ddpmpp-edm-gpus3-batch15-fp32-T2_ddpm/network-snapshot-001658.pkl'\n",
    "# net_save='/data/edm_outputs/00002-T1-uncond-ddpmpp-edm-gpus3-batch15-fp32-T1_ddpm/network-snapshot-001005.pkl'\n",
    "\n",
    "with dnnlib.util.open_url(net_save, verbose=(dist.get_rank() == 0)) as f:\n",
    "        net = pickle.load(f)['ema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = None\n",
    "lat = torch.randn(1,2,640,320)\n",
    "t = torch.tensor(1.)[None]\n",
    "# # print(net.model.img_resolution)\n",
    "# # print(net.in_channels)\n",
    "# # print(net.out_channels)\n",
    "# # print(net.label_dim)\n",
    "# # print(net.augment_dim)\n",
    "# # print(net.model_channels)\n",
    "# # print(net.channel_mult)\n",
    "denoised = net.model(lat, t, class_labels)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type='SongUNet'\n",
    "embedding_type='positional'\n",
    "encoder_type='standard'\n",
    "decoder_type='standard'\n",
    "channel_mult_noise=1\n",
    "resample_filter=[1,1]\n",
    "model_channels=128\n",
    "channel_mult=[2,2,2]\n",
    "img_resolution = 318\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "\n",
    "net1 = SongUNet(img_resolution=img_resolution, in_channels=in_channels,\n",
    "                out_channels=out_channels, channel_mult=channel_mult)\n",
    "edmNet = EDMPrecond(img_resolution=img_resolution,img_channels=in_channels,\n",
    "                    label_dim = 0, model_type=model_type, channel_mult=channel_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 158 but got size 159 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m1.\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# print(t.shape)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# denoised = net1(lat, t[None], class_labels)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m denoised_EDM \u001b[39m=\u001b[39m edmNet(lat,t,class_labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/edm/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/edm/training/networks.py:674\u001b[0m, in \u001b[0;36mEDMPrecond.forward\u001b[0;34m(self, x, sigma, class_labels, force_fp32, **model_kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m c_in \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma_data \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m sigma \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msqrt()\n\u001b[1;32m    672\u001b[0m c_noise \u001b[39m=\u001b[39m sigma\u001b[39m.\u001b[39mlog() \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m--> 674\u001b[0m F_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel((c_in \u001b[39m*\u001b[39;49m x)\u001b[39m.\u001b[39;49mto(dtype), c_noise\u001b[39m.\u001b[39;49mflatten(), class_labels\u001b[39m=\u001b[39;49mclass_labels, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m    675\u001b[0m \u001b[39massert\u001b[39;00m F_x\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtype\n\u001b[1;32m    676\u001b[0m D_x \u001b[39m=\u001b[39m c_skip \u001b[39m*\u001b[39m x \u001b[39m+\u001b[39m c_out \u001b[39m*\u001b[39m F_x\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/envs/edm/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/edm/training/networks.py:361\u001b[0m, in \u001b[0;36mSongUNet.forward\u001b[0;34m(self, x, noise_labels, class_labels, augment_labels)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m         \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m block\u001b[39m.\u001b[39min_channels:\n\u001b[0;32m--> 361\u001b[0m             x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x, skips\u001b[39m.\u001b[39;49mpop()], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    362\u001b[0m         x \u001b[39m=\u001b[39m block(x, emb)\n\u001b[1;32m    363\u001b[0m \u001b[39mreturn\u001b[39;00m aux\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 158 but got size 159 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "class_labels = None\n",
    "lat = torch.randn(1,2,318,318)\n",
    "t = torch.tensor(1.)\n",
    "# print(t.shape)\n",
    "# denoised = net1(lat, t[None], class_labels)\n",
    "denoised_EDM = edmNet(lat,t,class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
